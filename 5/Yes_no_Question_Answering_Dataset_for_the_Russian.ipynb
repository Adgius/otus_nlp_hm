{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QIYLg3NxASTW"
      },
      "outputs": [],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import re\n",
        "import numpy as np\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.optim import Adam\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "from transformers import get_scheduler\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "metadata": {
        "id": "V_jg9Ek0Ay8g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget --no-check-certificate https://russiansuperglue.com/tasks/download/DaNetQA"
      ],
      "metadata": {
        "id": "l34-W5L2A7D5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip DaNetQA -d QA"
      ],
      "metadata": {
        "id": "S3g2cWp7ZcHb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = pd.read_json('/content/QA/DaNetQA/train.jsonl', orient='records', lines = True)\n",
        "val = pd.read_json('/content/QA/DaNetQA/val.jsonl', orient='records', lines = True)\n",
        "test = pd.read_json('/content/QA/DaNetQA/test.jsonl', orient='records', lines = True)\n",
        "\n",
        "print('Train size:', len(train))\n",
        "print('Val size:', len(val))\n",
        "print('Test size:', len(test))\n",
        "print('\\n')\n",
        "print('Train labels counts\\n', train['label'].value_counts().to_dict(), '\\n')\n",
        "print('Eval labels counts\\n', val['label'].value_counts().to_dict(), '\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LnS7vtkeZlrw",
        "outputId": "20bc71fc-8daf-41d7-ae4b-f8ff0fdd896c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train size: 1749\n",
            "Val size: 821\n",
            "Test size: 805\n",
            "\n",
            "\n",
            "Train labels counts\n",
            " {True: 1061, False: 688} \n",
            "\n",
            "Eval labels counts\n",
            " {True: 412, False: 409} \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model"
      ],
      "metadata": {
        "id": "R4ho_KBZaVFl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"ai-forever/ruBert-base\")\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"ai-forever/ruBert-base\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u9XO3yueajyE",
        "outputId": "f27d5309-c10f-4eb5-b2c5-104a16632528"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at ai-forever/ruBert-base were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at ai-forever/ruBert-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "model.to(device)\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tlcz8BFxc3pr",
        "outputId": "a8c4393b-c041-4810-d7b9-4bf7b1398378"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_len = 0\n",
        "\n",
        "# For every sentence...\n",
        "for sent in pd.concat([train['question'], train['passage']]):\n",
        "\n",
        "    # Tokenize the text and add `[CLS]` and `[SEP]` tokens.\n",
        "    input_ids = tokenizer.encode(sent, add_special_tokens=True)\n",
        "\n",
        "    # Update the maximum sentence length.\n",
        "    max_len = max(max_len, len(input_ids))\n",
        "\n",
        "print('Max sentence length: ', max_len) # Больше максимально возможного"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fA_D7pZHanoo",
        "outputId": "de1429bf-91b9-4d79-9cb7-c6678f022ae0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Max sentence length:  745\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class TrainDataset(Dataset):\n",
        "    \n",
        "    def __init__(self, df):\n",
        "        self.df = df.reset_index(drop=True).drop(columns='idx')\n",
        "\n",
        "    def tokenize(self, text1, text2):\n",
        "        return tokenizer(text1, text2, return_tensors='pt', padding='max_length', truncation=True, max_length=512)\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.df.shape[0]\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        row = self.df.iloc[index, :]\n",
        "        output = self.tokenize(row['question'], row['passage'])\n",
        "        output.update({'labels': torch.tensor(row['label'].astype(int))})\n",
        "        return {k: v.reshape(-1).to(device) for k, v in output.items()}\n",
        "\n",
        "class TestDataset(Dataset):\n",
        "    \n",
        "    def __init__(self, df):\n",
        "        self.df = df.reset_index(drop=True).drop(columns='idx')\n",
        "\n",
        "    def tokenize(self, text1, text2):\n",
        "        return tokenizer(text1, text2, return_tensors='pt', padding='max_length', truncation=True, max_length=512)\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.df.shape[0]\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        row = self.df.iloc[index, :]\n",
        "        output = self.tokenize(row['question'], row['passage'])\n",
        "        return {k: v.reshape(-1).to(device) for k, v in output.items()}\n",
        "        \n",
        "\n",
        "train_ds = TrainDataset(train)\n",
        "train_dataloader = DataLoader(train_ds, batch_size=8, shuffle=True)\n",
        "\n",
        "eval_ds = TrainDataset(val)\n",
        "eval_dataloader = DataLoader(eval_ds, batch_size=8)\n",
        "\n",
        "test_ds = TestDataset(test)\n",
        "test_dataloader = DataLoader(test_ds, batch_size=8)"
      ],
      "metadata": {
        "id": "V0zly7xGa9ba"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = Adam(model.parameters(), lr=5e-6)\n",
        "\n",
        "num_epochs = 5\n",
        "num_training_steps = num_epochs * len(train_dataloader)\n",
        "lr_scheduler = get_scheduler(\n",
        "    \"linear\",\n",
        "    optimizer=optimizer,\n",
        "    num_warmup_steps=0,\n",
        "    num_training_steps=num_training_steps\n",
        ")"
      ],
      "metadata": {
        "id": "lIBTgcwmCOoB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(train_dataloader, num_epochs):\n",
        "    model.train()\n",
        "    for epoch in range(num_epochs):\n",
        "        print(f'Epoch {epoch+1} \\n -------------------')\n",
        "        for n_batch, batch in enumerate(train_dataloader):\n",
        "            outputs = model(**batch)\n",
        "            loss = outputs.loss\n",
        "            if n_batch % 50 == 0:\n",
        "                loss_value, current = loss.item(), n_batch * batch['input_ids'].shape[0]\n",
        "                print(f\"Loss train: {loss_value:>7f}  [{current:>5d}/{len(train_ds):>5d}]\")\n",
        "                print('Evaluating...')\n",
        "                preds, true = test_model(eval_dataloader, eval=True)\n",
        "                print(f'Accuracy = {accuracy_score(preds, true):>3f}\\n')\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            lr_scheduler.step()\n",
        "            optimizer.zero_grad() \n",
        "\n",
        "def test_model(test_dataloader, eval=False):\n",
        "    model.eval()\n",
        "    y_pred = np.array([])\n",
        "    y_true = np.array([])\n",
        "    for n_batch, batch in enumerate(test_dataloader):\n",
        "        if eval:\n",
        "            y_true = np.hstack([y_true, batch['labels'].cpu().numpy().reshape(-1)])\n",
        "        outputs = model(**batch)\n",
        "        y_pred = np.hstack([y_pred, outputs['logits'].argmax(axis=1).detach().cpu().numpy()])\n",
        "    return y_pred, y_true"
      ],
      "metadata": {
        "id": "0k0RCCPkeBl-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_model(train_dataloader, num_epochs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DTN-6ESHfEud",
        "outputId": "e20dc797-1bec-4ab7-d21d-a3671cbad507"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 \n",
            " -------------------\n",
            "Loss train: 0.669859  [    0/ 1749]\n",
            "Evaluating...\n",
            "Accuracy = 0.554202\n",
            "\n",
            "Loss train: 0.619839  [  400/ 1749]\n",
            "Evaluating...\n",
            "Accuracy = 0.510353\n",
            "\n",
            "Loss train: 0.607884  [  800/ 1749]\n",
            "Evaluating...\n",
            "Accuracy = 0.533496\n",
            "\n",
            "Loss train: 0.529855  [ 1200/ 1749]\n",
            "Evaluating...\n",
            "Accuracy = 0.538368\n",
            "\n",
            "Loss train: 0.690921  [ 1600/ 1749]\n",
            "Evaluating...\n",
            "Accuracy = 0.540804\n",
            "\n",
            "Epoch 2 \n",
            " -------------------\n",
            "Loss train: 0.434038  [    0/ 1749]\n",
            "Evaluating...\n",
            "Accuracy = 0.548112\n",
            "\n",
            "Loss train: 0.425070  [  400/ 1749]\n",
            "Evaluating...\n",
            "Accuracy = 0.551766\n",
            "\n",
            "Loss train: 0.559670  [  800/ 1749]\n",
            "Evaluating...\n",
            "Accuracy = 0.550548\n",
            "\n",
            "Loss train: 0.421098  [ 1200/ 1749]\n",
            "Evaluating...\n",
            "Accuracy = 0.551766\n",
            "\n",
            "Loss train: 0.418260  [ 1600/ 1749]\n",
            "Evaluating...\n",
            "Accuracy = 0.573691\n",
            "\n",
            "Epoch 3 \n",
            " -------------------\n",
            "Loss train: 0.299250  [    0/ 1749]\n",
            "Evaluating...\n",
            "Accuracy = 0.583435\n",
            "\n",
            "Loss train: 0.354687  [  400/ 1749]\n",
            "Evaluating...\n",
            "Accuracy = 0.585871\n",
            "\n",
            "Loss train: 0.441581  [  800/ 1749]\n",
            "Evaluating...\n",
            "Accuracy = 0.565164\n",
            "\n",
            "Loss train: 0.349981  [ 1200/ 1749]\n",
            "Evaluating...\n",
            "Accuracy = 0.587089\n",
            "\n",
            "Loss train: 0.128512  [ 1600/ 1749]\n",
            "Evaluating...\n",
            "Accuracy = 0.576127\n",
            "\n",
            "Epoch 4 \n",
            " -------------------\n",
            "Loss train: 0.250288  [    0/ 1749]\n",
            "Evaluating...\n",
            "Accuracy = 0.583435\n",
            "\n",
            "Loss train: 0.055950  [  400/ 1749]\n",
            "Evaluating...\n",
            "Accuracy = 0.574909\n",
            "\n",
            "Loss train: 0.055820  [  800/ 1749]\n",
            "Evaluating...\n",
            "Accuracy = 0.583435\n",
            "\n",
            "Loss train: 0.196745  [ 1200/ 1749]\n",
            "Evaluating...\n",
            "Accuracy = 0.591961\n",
            "\n",
            "Loss train: 0.132409  [ 1600/ 1749]\n",
            "Evaluating...\n",
            "Accuracy = 0.594397\n",
            "\n",
            "Epoch 5 \n",
            " -------------------\n",
            "Loss train: 0.047186  [    0/ 1749]\n",
            "Evaluating...\n",
            "Accuracy = 0.588307\n",
            "\n",
            "Loss train: 0.036027  [  400/ 1749]\n",
            "Evaluating...\n",
            "Accuracy = 0.590743\n",
            "\n",
            "Loss train: 0.033930  [  800/ 1749]\n",
            "Evaluating...\n",
            "Accuracy = 0.589525\n",
            "\n",
            "Loss train: 0.048901  [ 1200/ 1749]\n",
            "Evaluating...\n",
            "Accuracy = 0.600487\n",
            "\n",
            "Loss train: 0.026642  [ 1600/ 1749]\n",
            "Evaluating...\n",
            "Accuracy = 0.601705\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UdhXtHjiftsa",
        "outputId": "0b5d8d5f-4bd8-4421-a8ac-26b49a77beb4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_pretrained('drive/MyDrive/OTUS/qa')\n",
        "tokenizer.save_pretrained('drive/MyDrive/OTUS/qa')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jUw8cIGttRjQ",
        "outputId": "a63b867c-0bb8-41e1-8545-1dacb55aa221"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('drive/MyDrive/OTUS/qa/tokenizer_config.json',\n",
              " 'drive/MyDrive/OTUS/qa/special_tokens_map.json',\n",
              " 'drive/MyDrive/OTUS/qa/vocab.txt',\n",
              " 'drive/MyDrive/OTUS/qa/added_tokens.json',\n",
              " 'drive/MyDrive/OTUS/qa/tokenizer.json')"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_logits, _ = test_model(test_dataloader, eval=False)"
      ],
      "metadata": {
        "id": "-sHZcXO_tfwG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output = [\"true\" if i == 1 else \"false\"  for i in test_logits]\n",
        "output = [f'{{\"idx\": {n}, \"label\": \"{i}\"}}' for n, i in enumerate(output)]"
      ],
      "metadata": {
        "id": "L6wuGz8Zt7Z0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('DaNetQA.jsonl', 'w') as f:\n",
        "    f.writelines('\\n'.join(output))"
      ],
      "metadata": {
        "id": "haQ9yph5uC_H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lHzUTtFquHTB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}